Sessions forUNIX and Shell ProgrammingA TextbookBehrouz A. Forouzan and Richard F. GilbergBrooks/Cole Publishing( ISBN 0 534-95159-7)COPYRIGHT (c) 2003 the Wadsworth Group. Brooks/Cole is an imprint of the Wadsworth Group, a division of Thomson Learning, Inc. Thomson Learning(tm) is a trademark used herein under license.============================================================Chapter 6 ------------------------------------------------------------Session 6.1  The Basic cat Command$ cat file1 file2 file3This is file1.This is file2.This is file3.------------------------------------------------------------Session 6.2  Displaying a File with cat$ cat TheRavenV1Once upon a midnight dreary, while I pondered, weak and weary,Over many a quaint and curious volume of forgotten loreWhile I nodded, nearly napping, suddenly there came a tapping,As of someone gently rapping, rapping at my chamber door."'Tis some visitor," I muttered, "tapping at my chamber doorOnly this and nothing more."------------------------------------------------------------Session 6.3 Creating a File with cat$ cat > goodStudentsNow is the timefor all good studentsto come to the aidof their college.------------------------------------------------------------Session 6.4. Displaying Nonprintable Characters$ cat -vet catExampleThere is a tab between the numbers on the next line$1^I2^I3^I4^I5$$There are spaces at the end of the next line$One two buckle my shoe                      $The last character in this line is the bell^G$------------------------------------------------------------Session 6.5  catExample with No Options$ cat catExampleThere is a tab between the numbers on the next line1       2       3       4       5There are spaces at the end of the next lineOne two buckle my shoeThe last character in this line is the bell------------------------------------------------------------Session 6.6  Numbered Lines$ cat -n goodStudents catExample     1: Now is the time     2: for all good students     3: to come to the aid     4: of their college.     1: There is a tab between the numbers on the next line     2: 1       2       3       4       5     3:     4: There are spaces at the end of the next line     5: One two buckle my shoe     6:     7: The last character in this line is the bell------------------------------------------------------------Session 6.7 The head Command$ head -2 goodStudentsNow is the timefor all good students------------------------------------------------------------Session 6.8 Multiple Files with head Command$ head -2 goodStudents TheRaven==> goodStudents <==Now is the timefor all good students==> TheRaven <==Once upon a midnight dreary, while I pondered, weak and weary,Over many a quaint and curious volume of forgotten lore------------------------------------------------------------Session 6.9  Using the tail Option$ tail -2r goodStudentsof their college.to come to the aid------------------------------------------------------------Session 6.10 Extract Lines from Center of File$ head -13 TheRaven | tail +8Ah, distinctly I remember it was in the bleak December;And each separate dying ember wrought its ghost upon the floor.Eagerly I wished the morrow, -- vainly I had sought to borrowFrom my books surcease of sorrow -- sorrow for the lost LenoreFor the rare and radiant maiden whom the angels name LenoreNameless here for evermore.------------------------------------------------------------Session 6.11. Example of cut Command$ cut -c1-14,19-25 censusFixedChicago       2783726Houston       1630553Los Angeles   3485398New York      7322564Philadelphia  1585577------------------------------------------------------------Session 6.12   Cutting Piped Input$ ls -l | cut -c56-70,36-42  5781 TheRaven   721 census   824 censusFixed   512 mail   868 yanks------------------------------------------------------------Session 6.13 Overlapped cut Ranges$ ls -l | cut -c56-70,36-60  5781 Apr  5 12:53 TheRaven   698 May 14 13:18 census   823 May 13 18:39 censusFixed   512 Apr 10 21:25 mail   868 Mar 27 14:30 yanks------------------------------------------------------------Session 6.14 Error in cut Ranges$ ls -l | cut -c56-70,36-6Bad list for c/f option------------------------------------------------------------Session 6.15 Extract Field 1$ cut -f1 censusTabChicagoHoustonLos AngelesNew YorkPhiladelphia ------------------------------------------------------------Session 6.16 Extract City and Population Fields$ cut -f1,3-5 censusTabChicago 2783726 3005072 1434029Houston 1630553 1595138 1049300Los Angeles     3485398 2968528 1791011New York        7322564 7071639 3314000Philadelphia    1585577 1688210 736895------------------------------------------------------------Session 6.17  Using Slash for Field Separator$ cat censusSlashChicago/IL/2783726/3005072/1434029Houston/TX/1630553/1595138/1049300Los Angeles/CA/3485398/2968528/1791011New York/NY/7322564/7071639/3314000Philadelphia/PA/1585577/1688210/736895$ cut -f1,3,5 -d"/" censusSlashChicago/2783726/1434029Houston/1630553/1049300Los Angeles/3485398/1791011New York/7322564/3314000Philadelphia/1585577/736895------------------------------------------------------------Session 6.18 Pasting Two Files$ paste fileOdd fileEven1 11 111        2 383 33 333        4  85 55 555        6 487 77 777        8 229 99 999        0 10------------------------------------------------------------Session 6.19 Pasting Files of Different Lengths$ paste fileOdd fileEven21 11 111        2 383 33 333        4  85 55 555        6 487 77 7779 99 999$ paste fileEven2 fileOdd2 38    1 11 1114  8    3 33 3336 48    5 55 555        7 77 777        9 99 999------------------------------------------------------------Session 6.20 Using paste with Three Files$ paste -d"\t#" fileOddEven fileOdd fileEven1       1#22       3#43       5#64       7#5       9#------------------------------------------------------------Session 6.21 Pasting Files with Rotating Delimiters$ paste -d"\t#" fileOddEven fileOdd fileEven fileOddEven fileOdd1       1#2     1#12       3#4     2#33       5#6     3#54       7#      4#75       9#      5#9------------------------------------------------------------Session 6.22 Sort by City$ sort +0 -1 censusSpaceChicago IL 2783726 3005072 1434029Houston TX 1630553 1595138 1049300Los_Angeles CA 3485398 2968528 1791011New_York NY 7322564 7071639 3314000Philadelphia PA 1585577 1688210 736895------------------------------------------------------------Session 6.23 Sort by State$ sort +1 -2 censusSpaceLos_Angeles CA 3485398 2968528 1791011Chicago IL 2783726 3005072 1434029New_York NY 7322564 7071639 3314000Philadelphia PA 1585577 1688210 736895Houston TX 1630553 1595138 1049300------------------------------------------------------------Session 6.24 Check Sort Sequence$ sort -c +0 -1 census$ sort -c +1 -2 censusdisorder: Los_Angeles   CA      3485398 2968528 1791011------------------------------------------------------------Session 6.25 Change Sort Delimiter$ sort -t'&' +1 -2 censusAmpLos Angeles     &CA     &3485398        &2968528        &1791011Chicago         &IL     &2783726        &3005072        &1434029New York        &NY     &7322564        &7071639        &3314000Philadelphia    &PA     &1585577        &1688210        &736895Houston         &TX     &1630553        &1595138        &1049300------------------------------------------------------------Session 6.26 Invalid Numeric Sort$ sort +4 censusHouston         TX      1630553 1595138 1049300Chicago         IL      2783726 3005072 1434029Los_Angeles     CA      3485398 2968528 1791011New_York        NY      7322564 7071639 3314000Philadelphia    PA      1585577 1688210 736895------------------------------------------------------------Session 6.27  Sort on Numeric Fields$ sort -n +4 census Philadelphia    PA      1585577 1688210 736895Houston         TX      1630553 1595138 1049300Chicago         IL      2783726 3005072 1434029Los_Angeles     CA      3485398 2968528 1791011New_York        NY      7322564 7071639 3314000------------------------------------------------------------Session 6.28 Merge Two Files$ sort -m males femalesAndreBettyDianaGeorgeMaiPhan------------------------------------------------------------Session 6.29  Sort Census Data by State$ sort -t'/' +1 -2 census10Phoenix         /AZ/1881/ 983403/ 789704/ 591142/17705Los Angeles     /CA/1850/3485398/2968528/1791011/19906San Diego       /CA/1850/1110549/ 875538/ 553612/18651Chicago         /IL/1837/2783726/3005072/1434029/20349Detroit         /MI/1815/1027974/1203368/ 441736/19660New York        /NY/1898/7322564/7071639/3314000/22645Philadelphia    /PA/1701/1585577/1688210/ 736895/19750Dallas          /TX/1856/1006877/ 904599/ 649527/19485Houston         /TX/1837/1630553/1595138/1049300/17598San Antonio     /TX/1837/ 935933/ 785940/ 446701/14144------------------------------------------------------------Session 6.30 Eliminate Duplicate Sort Fields in Sort$ sort -t'/' -u +1 -2 census10Phoenix         /AZ/1881/ 983403/ 789704/ 591142/17705San Diego       /CA/1850/1110549/ 875538/ 553612/18651Chicago         /IL/1837/2783726/3005072/1434029/20349Detroit         /MI/1815/1027974/1203368/ 441736/19660New York        /NY/1898/7322564/7071639/3314000/22645Philadelphia    /PA/1701/1585577/1688210/ 736895/19750San Antonio     /TX/1837/ 935933/ 785940/ 446701/14144------------------------------------------------------------Session 6.31Sort in Descending Sequence$ sort -nr +2 -3 censusNew_York        NY      7322564 7071639 3314000Los_Angeles     CA      3485398 2968528 1791011Chicago         IL      2783726 3005072 1434029Houston         TX      1630553 1595138 1049300Philadelphia    PA      1585577 1688210 736895------------------------------------------------------------Session 6.32 Sort Descending-Method 2$ sort +2nr -3 censusNew_York        NY      7322564 7071639 3314000Los_Angeles     CA      3485398 2968528 1791011Chicago         IL      2783726 3005072 1434029Houston         TX      1630553 1595138 1049300Philadelphia    PA      1585577 1688210 7368950------------------------------------------------------------Session 6.33 Sort Ignoring Leading Blanks$ sort -b +1 -2 censusBlanksLos_Angeles     CA    3485398    2968528    1791011Chicago         IL    2783726    3005072    1434029New_York        NY    7322564    7071639    3314000Philadelphia    PA    1585577    1688210     736895Houston         TX    1630553    1595138    1049300------------------------------------------------------------Session 6.34 Sort Special Characters-The Wrong Way$ sort sortGlossary!       notASCII   American Standard Code for Information Interchange\       see escapeappend  To add at the end of a filebit     Binary digit; 0 or 1escape  The backslash character used to indicate a special codefile    A collection of related dataman     UNIX command for documentation (Manual)sort    To arrange data in a specified order------------------------------------------------------------Session 6.35 Sort Special Characters-The Right Way$ sort -d sortGlossary!       not\       see escapeASCII   American Standard Code for Information Interchangeappend  To add at the end of a filebit     Binary digit; 0 or 1escape  The backslash character used to indicate a special codefile    A collection of related dataman     UNIX command for documentation (Manual)sort    To arrange data in a specified order------------------------------------------------------------Session 6.36 Fold Upper- and Lowercase in Sort$ sort -df sortGlossary!       not\       see escapeappend  To add at the end of a fileASCII   American Standard Code for Information Interchangebit     Binary digit; 0 or 1escape  The backslash character used to indicate a special codefile    A collection of related dataman     UNIX command for documentation (Manual)sort    To arrange data in a specified order------------------------------------------------------------Session 6.37 Multiple-Pass Sort$ sort -t'/' +1 -3 census10Phoenix         /AZ/983403/789704/591142/17705San Diego       /CA/1110549/875538/553612/18651Los Angeles     /CA/3485398/2968528/1791011/19906Chicago         /IL/2783726/3005072/1434029/20349Detroit         /MI/1027974/1203368/441736/19660New York        /NY/7322564/7071639/3314000/22645Philadelphia    /PA/1585577/1688210/736895/19750Dallas          /TX/1006877/904599/649527/19485Houston         /TX/1630553/1595138/1049300/17598San Antonio     /TX/935933/785940/446701/14144------------------------------------------------------------Session 6.38 Multiple-Pass Sort-ASCII and Numeric$ sort -t'/' +1 -2 +2n -3 census10Phoenix         /AZ/983403/789704/591142/17705San Diego       /CA/1110549/875538/553612/18651Los Angeles     /CA/3485398/2968528/1791011/19906Chicago         /IL/2783726/3005072/1434029/20349Detroit         /MI/1027974/1203368/441736/19660New York        /NY/7322564/7071639/3314000/22645Philadelphia    /PA/1585577/1688210/736895/19750San Antonio     /TX/935933/785940/446701/14144Dallas          /TX/1006877/904599/649527/19485Houston         /TX/1630553/1595138/1049300/17598------------------------------------------------------------Session 6.39 Sort State Ascending, Population Descending$ sort -t'/' +1 -2 +2nr -3 census10Phoenix         /AZ/983403/789704/591142/17705Los Angeles     /CA/3485398/2968528/1791011/19906San Diego       /CA/1110549/875538/553612/18651Chicago         /IL/2783726/3005072/1434029/20349Detroit         /MI/1027974/1203368/441736/19660New York        /NY/7322564/7071639/3314000/22645Philadelphia    /PA/1585577/1688210/736895/19750Houston         /TX/1630553/1595138/1049300/17598Dallas          /TX/1006877/904599/649527/19485San Antonio     /TX/935933/785940/446701/14144------------------------------------------------------------Session 6.40  Find Largest City in Each State$ sort -b +1 -2 +2n -3 census20 | sort -bu +1 -2Phoenix           AZ   983403  789704  591142 17705Los_Angeles       CA  3485398 2968528 1791011 19906Washington        DC   606900  638432  283702 24845Jacksonville      FL   672971  571003  325187 16215Chicago           IL  2783726 3005072 1434029 20349Indianapolis      IN   744952  711539  405829 18080Boston            MA   574283  562994  297200 23746Baltimore         MD   736014  786741  346187 20267Detroit           MI  1027974 1203368  441736 19660New_York          NY  7322564 7071639 3314000 22645Columbus          OH   632910  565021  343288 17178Philadelphia      PA  1585577 1688210  736895 19750Memphis           TN   610337  646174  337450 16484Houston           TX  1630553 1595138 1049300 17598Milwaukee         WI   628088  636297  306256 18842------------------------------------------------------------Session 6.41Translate Vowels to Uppercase$ tr "aeiou" "AEIOU"It is very easy to use TRANSLATE.        #inputIt Is vEry EAsy tO UsE TRANSLATE.        #output------------------------------------------------------------Session 6.42 Translate Strings Don't Match$ tr "aeiou" "AE?"             # Case 1: string2 is shorter than string1It is very easy to use translate.It ?s vEry EAsy t? ?sE trAnslAtE.$ tr "aei" "AEIOU"             # Case 2: string1 is shorter than string2It is very easy to use translate.It Is vEry EAsy to usE trAnslAtE.------------------------------------------------------------Session 6.43 Delete Characters Using Translate$ tr -d "aeiouAEIOU"It is very easy to use TRANSLATEt s vry sy t s TRNSLT------------------------------------------------------------Session 6.44 Squeeze Output with Translate$ tr -s "ie" "dd"The fiend did dastardly deedsThd fdnd d dastardly ds------------------------------------------------------------Session 6.45 Using Translate's Complement Option$ tr -c "aeiou" "*"It is very easy to use TRANSLATE.***i***e***ea****o*u*e***********------------------------------------------------------------Session 6.46 Using Translate to Parse Words$ tr -cs "A-Za-z" "\n" <dastardly.txtThedastardlyfienddiddastardlydeedsHewastrulydastardly------------------------------------------------------------Session 6.47 Using Translate to Parse Words-Part 2$ tr -cs "A-Za-z" "\012" <dastardly.txt | sort -ufdastardlydeedsdidfiendHeThetrulywas------------------------------------------------------------Session 6.48 Basic Unique Command$ uniq uniqFile5 completely duplicate linesNot a duplicate--next duplicates first 55 completely duplicate linesLast 3 fields duplicate: one two threeThe next 3 lines are duplicate after char 5abcde Duplicate to endfghij Duplicate to endklmno Duplicate to end------------------------------------------------------------Session 6.49 Nonduplicated Lines$ uniq -u uniqFileNot a duplicate--next duplicates first 55 completely duplicate linesThe next 3 lines are duplicate after char 5abcde Duplicate to endfghij Duplicate to endklmno Duplicate to end------------------------------------------------------------Session 6.50 Only Duplicated Lines$ uniq -d uniqFile5 completely duplicate linesLast 3 fields duplicate: one two three------------------------------------------------------------Session 6.51Count Duplicated Lines$ uniq -c uniqFile   5 5 completely duplicate lines   1 Not a duplicate--next duplicates first 5   1 5 completely duplicate lines   3 Last 3 fields duplicate: one two three   1 The next 3 lines are duplicate after char 5   1 abcde Duplicate to end   1 fghij Duplicate to end   1 klmno Duplicate to end------------------------------------------------------------Session 6.52 Skip Leading Fields$ uniq -d -f 4 uniqFile5 completely duplicate linesLast 3 fields duplicate: one two threeabcde Duplicate to end------------------------------------------------------------Session 6.53 Skip Leading Characters$ uniq -d -s 5 uniqFile5 completely duplicate linesLast 3 fields duplicate: one two threeabcde Duplicate to end------------------------------------------------------------Session 6.54 Common wc Combinations$ wc TheRaven           116           994          5782 TheRaven$ wc TheRaven uniqFile           116           994          5782 TheRaven            14            72           445 uniqFile           130          1066          6227 total$ wc -c TheRaven          5782 TheRaven$ wc -l TheRaven           116 TheRaven$ wc -cl TheRaven           116          5782 TheRaven------------------------------------------------------------Session 6.55 The cmp Command without Options$ cat cmpFile11234567890$ cat cmpFile1.cpy1234567890$ cmp cmpFile1 cmpFile1.cpy$ cat cmpFile2123456as9u$ cmp cmpFile1 cmpFile2cmpFile1 cmpFile2 differ: char 8, line 2------------------------------------------------------------Session 6.56 The cmp Command with the List Option (-l)$ cmp -l cmpFile1 cmpFile2     8  67 141     9  70 163    11  60 165------------------------------------------------------------Session 6.57 The cmp Command with the Suppress List Option (-s)$ cmp cmpFile1 cmpFile1.cpy$ echo $?0$ cmp cmpFile1 cmpFile2$ echo $?1------------------------------------------------------------Session 6.58 Demonstration of the Change (c) and Append (a) Actions$ diff diff1 diff23c3< 3 x and y---> 3 y and x6,7c6,7< 6 x< 7 y---> 6 not x> 7 not y8a9,10> 9 extra line 1> A extra line 2------------------------------------------------------------Session 6.59 Demonstration of the Delete (d) Actions$ diff diff2 diff13c3< 3 y and x---> 3 x and y6,7c6,7< 6 not x< 7 not y---> 6 x> 7 y9,10d8< 9 extra line 1< A extra line 2------------------------------------------------------------Session 6.60 Directory Differences$ diff dir1 dir2diff dir1/file1 dir2/file12c2< 2---> 2 differentdiff dir1/file2 dir2/file23a4> D Extra line------------------------------------------------------------Session 6.61The comm Command$ comm comm1 comm2                one same                two samedifferent comm1        different comm2                same at line 4                same at line 5not in comm2                same at line 7                same at line 8        not in comm1                last line same 